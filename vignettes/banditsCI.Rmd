---
title: "banditsCI"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{my-vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(banditsCI)
set.seed(123)
cbPalette <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", 
               "#D55E00", "#CC79A7")

```

Set parameters. Here, we generate a dataset with 1000 observations in 4 equally 
sized batches, 5 covariates, and 4 arms. 
```{r parameters}
floor_start <- 5 # TODO discuss
floor_decay <- 0.9 # TODO discuss
batch_sizes <- c(250, 250, 250, 250)
A <- sum(batch_sizes)
p <- 5
K <- 4
```

Simulate data from an interacted linear model. 
```{r simlindata}
# Interacted linear model
X <- matrix(rnorm(A*p), ncol=p) # - X: covariates of shape [A, p]
# generate a linear model
coef <- c(rnorm(2), rnorm(ncol(X)-2, sd = 0.05))
y_latent <- X %*% coef
y <- as.numeric(cut(rank(y_latent),
                    # one group is twice as large as other groups
                    breaks = c(0, A*(2:(K+1)/(K+1))) ))
data <- generate_bandit_data(X = X, y = y, noise = 0)

```

Alternatively, we could use tree data (this is not evaluated here). 
```{r simtreedata, eval = FALSE}
data <- simple_tree_data(
  A=A,
  K=K,
  p=p,
  split = 0.6,
  noise_std = 0.5)
```

## For the contextual case
We run a contextual experiment. 
```{r contextual}
# access dataset components
xs <- data[[1]]$xs
ys <- data[[1]]$ys
results <- run_experiment(ys, floor_start, floor_decay, batch_sizes, xs)

# conditional means model
mu_hat <- ridge_muhat_lfo_pai(xs=xs, 
                              ws=results$ws, 
                              yobs=results$yobs, 
                              K=K, 
                              batch_sizes=batch_sizes)

mu_hat2d <- mu_hat[1,,]
for(i in 1:nrow(mu_hat2d)){
  mu_hat2d[i,] <- mu_hat[i,i,]
}

# inverse probability score 1[W_t=w]/e_t(w) of pulling arms, shape [A, K]
balwts <- calculate_balwts(results$ws, results$probs)

# plot the cumulative assignment graph for every arm and every batch size, x-axis is the number of observations, y-axis is the cumulative assignment
plot_cumulative_assignment(results, batch_sizes)


aipw_scores <- aw_scores(
  ws = results$ws, 
  yobs = results$yobs, 
  mu_hat = mu_hat2d, 
  K = ncol(results$ys),
  balwts = balwts)

```

```{r estimation, fig.width=10, fig.height=6}
# Get estimates for policies

## Define counterfactual policies
### Control policy matrix policy0. This is a matrix with A rows and K columns, where the elements in the first column are all 1s and the elements in the remaining columns are all 0s.
policy0 <- matrix(0, nrow = A, ncol = K)
policy0[,1] <- 1

### Treatment policies list policy1. This is a list with K elements, where each list contains a matrix with A rows and K columns. Identifier of treatment x: the x th column of the matrix in the x th policy in the list is 1.
policy1 <- lapply(1:K, function(x) {
  pol_mat <- matrix(0, nrow = A, ncol = K)
  pol_mat[,x] <- 1
  pol_mat
}
) 

## estimating the value Q(w) of a single arm w. Here we estimate all the arms in policy1 in turn. 
out_full <- output_estimates(
  policy1 = policy1, 
  gammahat = aipw_scores, 
  contextual_probs = results$probs)

# Get estimates for treatment effects of policies as contrast to control \delta(w_1, w_2) = E[Y_t(w_1) - Y_t(w_2)]. In Hadad, Vitor, et al (2021) there are two approaches.
## The first approach: use the difference in AIPW scores as the unbiased scoring rule for \delta (w_1, w_2)
### The following function implements the first approach by subtracting policy0, the control arm, from all the arms in policy1, except for the control arm itself.
out_full_te1 <- output_estimates(
  policy0 = policy0,
  policy1 = policy1[-1],  ## remove the control arm from policy1
  contrasts = 'combined',
  gammahat = aipw_scores, 
  contextual_probs = results$probs)

## The second approach takes asymptotically normal inference about \delta(w_1, w_2): \delta ^ hat (w_1, w_2) = Q ^ hat (w_1) - Q ^ hat (w_2)
out_full_te2 <- output_estimates(
  policy0 = policy0,
  policy1 = policy1[-1],  ## remove the control arm from policy1
  contrasts = 'separate',
  gammahat = aipw_scores, 
  contextual_probs = results$probs)


# Figure

# Combine the data frames into a single data frame
combinedMatrix <- do.call(rbind, out_full_te2)
combinedMatrix <- as.data.frame(combinedMatrix)

# Add an .id column to indicate the arm number
n_arms <- length(out_full_te2)
n_reps <- nrow(out_full_te2[[1]])
combinedMatrix$id <- rep(1:n_arms, each = n_reps)

# Add a column to indicate the arm name
n_arms <- n_arms+1
combinedMatrix$arm <- rep(paste0("arm", 2:n_arms), each = n_reps)

# Add a method column
values <- c("uniform", "non_contextual_minvar", "contextual_minvar", 
            "non_contextual_stablevar", "contextual_stablevar", "non_contextual_twopoint")
combinedMatrix$method <- rep(values, length.out = nrow(combinedMatrix))


# Create the plot
# Define a function for plotting each arm
plot_arm <- function(arm_data, arm_name) {
  # Sort the methods for consistent ordering
  arm_data <- arm_data[order(arm_data$method), ]
  
  # Number of methods
  n_methods <- nrow(arm_data)
  
  # Set the y-axis limits
  ylim <- c(1, n_methods)
  
  # Set the x-axis limits (adding some padding)
  xlim <- range(c(arm_data$estimate - 1.96*arm_data$std.error, 
                 arm_data$estimate + 1.96*arm_data$std.error))
  xlim <- xlim + c(-0.1*diff(xlim), 0.1*diff(xlim))
  
  # Create an empty plot
  plot(1, 1, xlim = xlim, ylim = ylim, type = "n", 
       xlab = "Coefficient Estimate", ylab = "",
       main = paste("Coefficients and Confidence Intervals (", arm_name, ")", sep = ""),
       yaxt = "n")  # suppress y-axis ticks/labels
  
  # Add points for each method
  points(arm_data$estimate, 1:n_methods, pch = 19, cex = 1.5)
  
  # Add error bars
  arrows(arm_data$estimate - 1.96*arm_data$std.error, 1:n_methods, 
         arm_data$estimate + 1.96*arm_data$std.error, 1:n_methods, 
         angle = 90, code = 3, length = 0.1)
  
  # Add method labels on the y-axis
  axis(2, at = 1:n_methods, labels = arm_data$method, las = 1)
}

# Set up a plotting layout with 2 columns
unique_arms <- unique(combinedMatrix$arm)
n_arms <- length(unique_arms)
par(mfrow = c(ceiling(n_arms/2), 2), mar = c(5, 12, 4, 4))

# Plot each arm
for(arm_name in unique_arms) {
  arm_data <- combinedMatrix[combinedMatrix$arm == arm_name, ]
  plot_arm(arm_data, arm_name)
}
```
## For the non-contextual case

We run a non-contextual experiment. 
```{r noncontextual}
results <- run_experiment(ys, floor_start, floor_decay, batch_sizes)

# inverse probability score 1[W_t=w]/e_t(w) of pulling arms, shape [A, K]
balwts <- calculate_balwts(results$ws, results$probs)

# plot the cumulative assignment graph for every arm and every batch size, x-axis is the number of observations, y-axis is the cumulative assignment
plot_cumulative_assignment(results, batch_sizes)


aipw_scores <- aw_scores(
  ws = results$ws, 
  yobs = results$yobs, 
  K = ncol(results$ys),
  balwts = balwts)

```

```{r estimation_nc, fig.width=10, fig.height=6}
# get two-dimensional probabilities
# TODO explain what's going on with probabilities
# TODO what happens with contextual variances when there's 2d probs/
probs <- results$probs[,1,]
# Get estimates for policies

## Define counterfactual policies
### Control policy matrix policy0. This is a matrix with A rows and K columns, where the elements in the first column are all 1s and the elements in the remaining columns are all 0s.
policy0 <- matrix(0, nrow = A, ncol = K)
policy0[,1] <- 1

### Treatment policies list policy1. This is a list with K elements, where each list contains a matrix with A rows and K columns. Identifier of treatment x: the x th column of the matrix in the x th policy in the list is 1.
policy1 <- lapply(1:K, function(x) {
  pol_mat <- matrix(0, nrow = A, ncol = K)
  pol_mat[,x] <- 1
  pol_mat
}
) 

## estimating the value Q(w) of a single arm w. Here we estimate all the arms in policy1 in turn. 
out_full <- output_estimates(
  policy1 = policy1, 
  gammahat = aipw_scores, 
  contextual_probs = probs)

# Get estimates for treatment effects of policies as contrast to control \delta(w_1, w_2) = E[Y_t(w_1) - Y_t(w_2)]. In Hadad, Vitor, et al (2021) there are two approaches.
## The first approach: use the difference in AIPW scores as the unbiased scoring rule for \delta (w_1, w_2)
### The following function implements the first approach by subtracting policy0, the control arm, from all the arms in policy1, except for the control arm itself.
out_full_te1 <- output_estimates(
  policy0 = policy0,
  policy1 = policy1[-1],  ## remove the control arm from policy1
  contrasts = 'combined',
  gammahat = aipw_scores, 
  contextual_probs = probs)

## The second approach takes asymptotically normal inference about \delta(w_1, w_2): \delta ^ hat (w_1, w_2) = Q ^ hat (w_1) - Q ^ hat (w_2)
out_full_te2 <- output_estimates(
  policy0 = policy0,
  policy1 = policy1[-1],  ## remove the control arm from policy1
  contrasts = 'separate',
  gammahat = aipw_scores, 
  contextual_probs = probs)


# Figure

# Combine the data frames into a single data frame
combinedMatrix <- do.call(rbind, out_full_te2)
combinedMatrix <- as.data.frame(combinedMatrix)

# Add an .id column to indicate the arm number
n_arms <- length(out_full_te2)
n_reps <- nrow(out_full_te2[[1]])
combinedMatrix$id <- rep(1:n_arms, each = n_reps)

# Add a column to indicate the arm name
n_arms <- n_arms+1
combinedMatrix$arm <- rep(paste0("arm", 2:n_arms), each = n_reps)

# Add a method column
values <- c("uniform", "non_contextual_minvar", "contextual_minvar", 
            "non_contextual_stablevar", "contextual_stablevar", "non_contextual_twopoint")
combinedMatrix$method <- rep(values, length.out = nrow(combinedMatrix))

# Create the plot
# Define a function for plotting each arm
plot_arm <- function(arm_data, arm_name) {
  # Sort the methods for consistent ordering
  arm_data <- arm_data[order(arm_data$method), ]
  
  # Number of methods
  n_methods <- nrow(arm_data)
  
  # Set the y-axis limits
  ylim <- c(1, n_methods)
  
  # Set the x-axis limits (adding some padding)
  xlim <- range(c(arm_data$estimate - 1.96*arm_data$std.error, 
                 arm_data$estimate + 1.96*arm_data$std.error))
  xlim <- xlim + c(-0.1*diff(xlim), 0.1*diff(xlim))
  
  # Create an empty plot
  plot(1, 1, xlim = xlim, ylim = ylim, type = "n", 
       xlab = "Coefficient Estimate", ylab = "",
       main = paste("Coefficients and Confidence Intervals (", arm_name, ")", sep = ""),
       yaxt = "n")  # suppress y-axis ticks/labels
  
  # Add points for each method
  points(arm_data$estimate, 1:n_methods, pch = 19, cex = 1.5)
  
  # Add error bars
  arrows(arm_data$estimate - 1.96*arm_data$std.error, 1:n_methods, 
         arm_data$estimate + 1.96*arm_data$std.error, 1:n_methods, 
         angle = 90, code = 3, length = 0.1)
  
  # Add method labels on the y-axis
  axis(2, at = 1:n_methods, labels = arm_data$method, las = 1)
}

# Set up a plotting layout with 2 columns
unique_arms <- unique(combinedMatrix$arm)
n_arms <- length(unique_arms)
par(mfrow = c(ceiling(n_arms/2), 2), mar = c(5, 12, 4, 4))

# Plot each arm
for(arm_name in unique_arms) {
  arm_data <- combinedMatrix[combinedMatrix$arm == arm_name, ]
  plot_arm(arm_data, arm_name)
}
```

